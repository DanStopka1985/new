--Теперь напишем запрос по поиску индивида по СНИЛС


--получаем случайный идентификатор индивида
-- (просто выбираем случайнымобразом строку из идентификаторов без привязки к типу идентификатора)
select code
from indiv_code
where id = (select (random() * max(id))::int from indiv_code);

--и затем ищем полученный код среди имеющихся СНИЛС и получаем индивида
select coalesce(
               (select concat_ws(' ', sname, fname, mname)
                from indiv
                where id = (select indiv_id
                              from indiv_code
                              where code = '5998ddb21630dfa8ac748ff9d9f96775' and type_id = 1)),
               'indiv not found'
           );

/*
запрос выполняется ~100ms
Вроде бы быстро, но попробуем запустить его 200ми пользователями
    -выполнить App1
    -сгенерировать pgbadger (SHIFT+CTRL+B)
    -посмотреть top timeconsuming queries (ALT+CTRL+J ; CTRL+C ; SHIFT+CTRL+W)
        file:///C:/PostgreSQL/data/logs/pg11/a.html#time-consuming-queries
*/

/*
Для 200 условных пользователей общее время выполнения составляет уже около минуты
Для такого малого количества данных удалось получить уже серьезную нагрузку
Самый долгий запрос выполняется около минуты
*/

/*
Чтобы это ускорить, нужно понять, что именно долго работает.
Мы не знаем как Postgres выполняет запросы, каким способом получает данные, мы только говорим, что нужно получить, а как получить - не говорим.
Если вкратце в Postgres есть планировщик, который строит для запроса оптимальный алгоритм выполнения (План запроса).
И затем выполняет этот алгоритм и достает нужные данные. Увидеть этот алгоритм нам поможет explain
https://postgrespro.ru/docs/postgrespro/9.6/sql-explain
подробнее можно ознакомиться
explain представляет план запроса в виде дерева, каждый узел дерева - какое-то действие

Что из этого мы будем смотреть:

analyze - говорит о том, что запрос надо выполнить и замерить, что по факту было затрачено
verbose - вывести дополнительную информацию о выполнении узлов, вывод колонок,
            используемые триггеры, названия псевдонимов и схем
Buffers говорит об используемой памяти так же для каждого узла
формат по умолчанию текст, его мы и будем использовать
*/
--Выполним explain для нашего запроса поиска сначала без параметров.
explain--(verbose, analyse, buffers)
select coalesce(
               (select concat_ws(' ', sname, fname, mname)
                from indiv
                where id = (select indiv_id
                              from indiv_code
                              where code = 'd0cd20f38f1c73cde6db4b8ce2fcffd6' and type_id = 1)),
               'indiv not found'
           );
/*
Узлы на нажних уровнях дерева (листьях) представляют собой первичные действия алгоритма - обычно это сканирование таблиц, индексов, констант.
Родительские узлы - следующие действия. И в корне получается результат выполнения запроса.
COST - стоимость – это относительная величина вычисляемая для выполняемого действия исходя из множества различных факторов,
    в частности настроек pg_settings, статистики, сложности стратегий и прочего. В общем случае чем меньше стоимость - тем быстрее выполняется запрос (но не всегда)
Первое число - стоимость запуска, второе - общая стоимость
В нашем случае сначала выполняется Parallel Seq Scan таблицы indiv_code - параллельное последовательное сканирование таблицы целиком c фильтрацией по искомому коду
и типу идентификатора.
Параллельное последовательное сканирование - это обычный seq scan выполняемый несколькими исполнителями параллельно, появилось в версии 9.6
Дальше идет сбор собранных данных (Gather).
Узел выше сканирует индекс pk_indiv по полученным данным из дочернего узла (Index Cond: (id = $1))
 (при создании первичного ключа, автоматически создается индекс)
Корневой узел возвращает результат запроса.
Теперь мы знаем как Postgres выполняет наш запрос и можем попытаться что-то изменить, чтобы его ускорить.
Сразу можем обратить внимание на то, что стоимость выполнения конечного узла и корневого не сильно отличается.
А так как стоимость корневого плана включает в себя стоимость всех его потомков -
 можно сделать вывод, что основную сложность алгоритма составляет конечный узел (parallel seq scan)
*/

/*Чтобы получить больше информации, выполним explain с параметрами (verbose, analyse, buffers)*/
explain(verbose, analyse, buffers)
select coalesce(
               (select concat_ws(' ', sname, fname, mname)
                from indiv
                where id = (select indiv_id
                              from indiv_code
                              where code = 'd0cd20f38f1c73cde6db4b8ce2fcffd6' and type_id = 1)),
               'indiv not found'
           );
/*
Здесь, кроме стоимости можно увидеть время выполнения каждого узла, какие данные узел возвращает и сколько памяти использует
Shared hit – это количество блоков считанных их кэша Postgres. Размер блока по умолчанию – 8кб.
Shared read – количество блоков считанных с диска.
Опять же, в общем случае - чем меньше памяти использует запрос, тем он лучше.
Можно увидеть, что и по памяти и по времени конечный узел не сильно отличается от корневого.
Для того, чтобы оптимизировать запрос мы должны изменить план его выполнения.
Как можно изменить план выполнения? Можно разными способами, например изменением настроек или изменением самого запроса.
Для примера отключим распараллеливание последовательного сканирования. и перезапустим explain
*/
set max_parallel_workers_per_gather = 0;
explain(verbose, analyse, buffers)
select coalesce(
               (select concat_ws(' ', sname, fname, mname)
                from indiv
                where id = (select indiv_id
                              from indiv_code
                              where code = 'd0cd20f38f1c73cde6db4b8ce2fcffd6' and type_id = 1)),
               'indiv not found'
           );
/*
Как видим, план изменился, parallel seq scan и gather превратились в seq scan.
Это для примера изменения стоимости настройками, план конечно же стал хуже,
если можно распараллелить - в общем случае, то лучше распараллелить
Вернем как было
*/
set max_parallel_workers_per_gather = 2;
explain(verbose, analyse, buffers)
select coalesce(
               (select concat_ws(' ', sname, fname, mname)
                from indiv i
                where i.id = (select indiv_id
                              from indiv_code
                              where code = 'd0cd20f38f1c73cde6db4b8ce2fcffd6' and type_id = 1)),
               'indiv not found'
           );
/*
Как мы выяснили, основную сложность алгоритма составляет конечный узел(seq scan), он же выполняется дольше всего и больше всего использует памяти.
Действительно, чтобы найти подходящие нам строки, необходимо просканировать всю таблицу и проверить выполняется ли условие.
Для ускорения поиска существуют вспомогательные структуры - индексы. Подобно поиску по оглавлению в книге - если
оглавления нет и нужно найти какую-то главу по названию, придется просматривать каждую страницу. Если есть оглавление,
то нужно просмотреть только страницу с оглавлением, найти нужную главу в нем и перейти на указанную страницу.
В нашем плане уже используется индекс (в узле Index Scan using pk_indiv on indiv) если бы его не было так же пришлось
бы сканировать всю таблицу.
Создадим индекс по коду идентификатора индивида
*/

create index if not exists indiv_code_idx on indiv_code(code);
/*И снова выполним explain*/
explain(verbose, analyse, buffers)
select coalesce(
               (select concat_ws(' ', sname, fname, mname)
                from indiv i
                where i.id = (select indiv_id
                              from indiv_code
                              where code = 'd0cd20f38f1c73cde6db4b8ce2fcffd6' and type_id = 1)),
               'indiv not found'
           );
/*
План изменился. Теперь вместо сканирования таблицы сканируется наш индекс.
Изменилось и время выполнения и потребление памяти (было Buffers: shared hit=9346; стало Buffers: shared read=3)
Но индексы бывают разные, а мы какой создали? В нашем скрипте на создание об этом ничего не сказано - только название и поле.
*/
create index if not exists indiv_code_idx on indiv_code(code);
/*
Чтобы посмотреть какой у нас индекс, выполним запрос
*/
select pg_get_indexdef('indiv_code_idx'::regclass);


/*
по умолчанию в postgres создается btree индекс
ради эксперимента создадим другой индекс на это же поле
Хэш индекс
*/

create index indiv_code_hash_idx on indiv_code using hash (code);
/*И снова выполним explain*/
explain(verbose, analyse, buffers)
select coalesce(
               (select concat_ws(' ', sname, fname, mname)
                from indiv i
                where i.id = (select indiv_id
                              from indiv_code
                              where code = 'd0cd20f38f1c73cde6db4b8ce2fcffd6' and type_id = 1)),
               'indiv not found'
           );
/*
Теперь стал использоваться именно хэш индекс
И по пямяти стало немного лучше. И стоимость меньше. Оптимизатор постгрес пытается выбрать план с наименьшей стоимостью
Почему же тогда Postgres по умолчанию создает индекс btree, который хуже чем хэш?
Для разных запросов разные индексы ведут себя по разному, для каких-то запросов определенные индексы вообще не будут работать.
Postgres не знает какие запросы мы будем выполнять, по этому по умолчанию разработчики выбрали самый универсальный.
*/





select pg_size_pretty(pg_table_size('indiv_code_hash_idx')) hash,
       pg_size_pretty(pg_table_size('indiv_code_idx'))      btree;
--drop index indiv_code_hash_idx;

--drop index indiv_code_idx